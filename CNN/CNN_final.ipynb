{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaNRqcAwElAFCS+Bx516AJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4NenT9B_dTow"},"outputs":[],"source":["# ë¦¬ì‚¬ì´ì¦ˆ - ë‚˜ë§Œ\n","import os\n","from PIL import Image, ImageOps\n","\n","input_folder = \"D:\\\\foodsnap_CNN\\\\ê±´ê°•ê´€ë¦¬ë¥¼ ìœ„í•œ ìŒì‹ ì´ë¯¸ì§€\\\\Training\\\\train\"\n","output_folder = \"D:\\\\foodsnap_CNN\\\\ê±´ê°•ê´€ë¦¬ë¥¼ ìœ„í•œ ìŒì‹ ì´ë¯¸ì§€\\\\Training\\\\train_p\" #ë¦¬ì‚¬ì´ì¦ˆ train\n","valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')\n","\n","def pad_and_resize_save(img_path, save_path, size=(224, 224)):\n","    try:\n","        img = Image.open(img_path)\n","        img_padded = ImageOps.pad(img, size, color=(0, 0, 0))\n","        img_padded.save(save_path)\n","        img.close()\n","        os.remove(img_path)  # ì›ë³¸ ì‚­ì œ\n","    except Exception as e:\n","        print(f\"âŒ ì—ëŸ¬ ë°œìƒ: {img_path} â†’ {e}\")\n","\n","# ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ\n","for root, dirs, files in os.walk(input_folder):\n","    rel_path = os.path.relpath(root, input_folder)\n","    save_dir = os.path.join(output_folder, rel_path)\n","    os.makedirs(save_dir, exist_ok=True)\n","    for file in files:\n","        if file.lower().endswith(valid_extensions):\n","            input_path = os.path.join(root, file)\n","            output_path = os.path.join(save_dir, file)\n","            pad_and_resize_save(input_path, output_path)\n","\n","print(f'âœ… padding + resize + ì›ë³¸ ì‚­ì œ ì™„ë£Œ â†’ ì €ì¥ ìœ„ì¹˜: {output_folder}')"]},{"cell_type":"code","source":["CHUNK_START = 1   # ë‚´ê°€ ë§¡ì€ ì²« ì²­í¬\n","CHUNK_END   = 10  # ë‚´ê°€ ë§¡ì€ ë§ˆì§€ë§‰ ì²­í¬\n","# 10ë‹¨ìœ„ / A 1-10 / B 11-20 / A 21-30 / B 31-40.....\n","## ê³„ì† ë²”ìœ„ ë°”ê¿”ê°€ë©° ì‹¤í–‰"],"metadata":{"id":"dBsWhPnvjKEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, gc, tensorflow as tf\n","from pathlib import Path\n","from tensorflow.keras.applications import MobileNetV3Large\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n","                                        ModelCheckpoint, LearningRateScheduler)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","CHUNKS_ROOT  = Path(r\"D:\\\\foodsnap_CNN\\\\ê±´ê°•ê´€ë¦¬ë¥¼ ìœ„í•œ ìŒì‹ ì´ë¯¸ì§€\\\\Training\\\\chunks\")\n","CKPT_DIR     = CHUNKS_ROOT.parent / \"ckpt\"      # ckpt ì €ì¥ í´ë”(Training/ckpt)\n","CKPT_DIR.mkdir(exist_ok=True)\n","\n","IMG_SIZE     = (224, 224)\n","BATCH_SIZE   = 64\n","EPOCHS_PER_CHUNK = 15          # ì²­í¬ë‹¹ epoch\n","UNFREEZE_STEP    = 40          # ì²­í¬ê°€ ë„˜ì–´ê°ˆ ë•Œë§ˆë‹¤ ë’¤ìª½ Në ˆì´ì–´ ë” í’€ê¸°\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ì œë„ˆë ˆì´í„° ê³µí†µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","datagen = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n","    rotation_range=30, width_shift_range=.25, height_shift_range=.25,\n","    shear_range=.25, zoom_range=.25, horizontal_flip=True, vertical_flip=True,\n","    brightness_range=[.8,1.2], validation_split=.1)\n","\n","def make_generators(chunk_dir:Path):\n","    train_gen = datagen.flow_from_directory(\n","        chunk_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n","        class_mode='categorical', subset='training')\n","    val_gen   = datagen.flow_from_directory(\n","        chunk_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n","        class_mode='categorical', subset='validation', shuffle=False)\n","    return train_gen, val_gen\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ë¹Œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","def build_model(num_classes:int, unfreeze_from:int=None):\n","    base = MobileNetV3Large(input_shape=(*IMG_SIZE,3),\n","                            include_top=False, weights='imagenet')\n","    if unfreeze_from is not None:\n","        for l in base.layers[:unfreeze_from]:  l.trainable = False\n","        for l in base.layers[unfreeze_from:]: l.trainable = True\n","    else:   # ì²« ì²­í¬: í—¤ë“œë§Œ í•™ìŠµ\n","        for l in base.layers: l.trainable = False\n","\n","    x = GlobalAveragePooling2D()(base.output)\n","    x = Dense(512, activation='relu')(x); x = Dropout(.3)(x)\n","    x = Dense(256, activation='relu')(x)\n","    out = Dense(num_classes, activation='softmax')(x)\n","    model = Model(base.input, out)\n","    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n","                  loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëŸ¬ë‹ë ˆì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","lr_sched = lambda e, lr: 1e-4 if e < 5 else 1e-5 if e < 10 else 5e-6\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì²­í¬ ìˆœì°¨ í•™ìŠµ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","if CHUNK_START > 1:\n","    latest_ckpt = CKPT_DIR / f\"train_chunk{CHUNK_START-1}.keras\"\n","else:\n","    latest_ckpt = None\n","\n","for idx, chunk_dir in enumerate(sorted(CHUNKS_ROOT.glob(\"train_chunk*\")), start=1):\n","    if not (CHUNK_START <= idx <= CHUNK_END):\n","        continue  # ë‚´ ì‘ì—… ë²”ìœ„ ì•„ë‹ˆë©´ skip\n","\n","    print(f\"\\nâ–¶ï¸  í•™ìŠµ ì‹œì‘: {chunk_dir.name}\")\n","\n","    # â–¶ï¸ Epoch ë™ì  ê²°ì •\n","    if idx <= 5:\n","        epochs = 20 # ê¸°ì´ˆ í•™ìŠµ ê°•í™”\n","    elif idx <= 30:\n","        epochs = 15\n","    else:\n","        epochs = 20 # íŒŒì¸íŠœë‹ ê°•í™”\n","\n","    train_gen, val_gen = make_generators(chunk_dir)\n","\n","    # â”€â”€ ëª¨ë¸ ì¤€ë¹„ â”€â”€\n","    if latest_ckpt is None:          # ì²« ì²­í¬\n","        model = build_model(train_gen.num_classes, unfreeze_from=None)\n","    else:                            # ì´í›„ ì²­í¬: ë” ë§ì€ ë ˆì´ì–´ í’€ì–´ fine-tune\n","        model = build_model(train_gen.num_classes, unfreeze_from=-UNFREEZE_STEP)\n","        model.load_weights(latest_ckpt)\n","\n","    # â”€â”€ ì½œë°± â”€â”€\n","    ckpt_path = CKPT_DIR / f\"{chunk_dir.name}.keras\"\n","    cbs = [\n","        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=.2, patience=3),\n","        LearningRateScheduler(lr_sched),\n","        ModelCheckpoint(str(ckpt_path), save_best_only=True, monitor='val_accuracy', verbose=1)\n","    ]\n","\n","    # â”€â”€ í•™ìŠµ â”€â”€\n","    print(f\"ğŸ“Œ Epoch ì„¤ì •: {epochs}íšŒ\")\n","    model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=cbs)\n","\n","    latest_ckpt = ckpt_path\n","    del train_gen, val_gen, model\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\n","print(f\"\\nğŸ‰ ëª¨ë“  ì²­í¬ í•™ìŠµ ì™„ë£Œ! ìµœì¢… ëª¨ë¸: {latest_ckpt}\")\n"],"metadata":{"id":"b-zk1M8hdXkI"},"execution_count":null,"outputs":[]}]}